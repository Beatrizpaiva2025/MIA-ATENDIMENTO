# ============================================================
# VERS√ÉO COMPLETA MULTIM√çDIA + PAINEL ADMIN - main.py
# ============================================================
# Bot WhatsApp com suporte a:
# ‚úÖ Mensagens de texto
# ‚úÖ Imagens (GPT-4 Vision) - Leitura de documentos
# ‚úÖ √Åudios (Whisper) - Transcri√ß√£o de voz
# ‚úÖ Painel Administrativo Completo
# ============================================================

from fastapi import FastAPI, Request, HTTPException, Form
from fastapi.responses import JSONResponse, HTMLResponse, RedirectResponse
from fastapi.staticfiles import StaticFiles
from fastapi.templating import Jinja2Templates
import os
import httpx
from openai import OpenAI
from datetime import datetime
from motor.motor_asyncio import AsyncIOMotorClient
import logging
from typing import Optional, Dict, Any, List
from pydantic import BaseModel
import traceback
import json
import base64
from io import BytesIO

# Importar rotas do admin
from admin_routes import router as admin_router
from admin_training_routes import router as training_router
from admin_controle_routes import router as controle_router

# ============================================================
# CONFIGURA√á√ÉO DE LOGGING
# ============================================================
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# ============================================================
# INICIALIZA√á√ÉO
# ============================================================
app = FastAPI(title="WhatsApp AI Platform - Legacy Translations")

# Templates
templates = Jinja2Templates(directory="templates")

# Clientes
openai_client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
# Usar mesma conex√£o do admin
from admin_training_routes import get_database
db = get_database()

# ============================================================
# INCLUIR ROTAS DO PAINEL ADMIN
# ============================================================
app.include_router(admin_router)
app.include_router(training_router)
app.include_router(controle_router)

# ============================================================
# CONFIGURA√á√ïES Z-API
# ============================================================
ZAPI_INSTANCE_ID = os.getenv("ZAPI_INSTANCE_ID")
ZAPI_TOKEN = os.getenv("ZAPI_TOKEN")
ZAPI_CLIENT_TOKEN = os.getenv("ZAPI_CLIENT_TOKEN")
ZAPI_URL = os.getenv("ZAPI_URL", "https://api.z-api.io")

# ============================================================
# MODELOS PYDANTIC
# ============================================================
class Message(BaseModel):
    phone: str
    message: str
    timestamp: datetime = datetime.now()
    role: str = "user"
    message_type: str = "text"

# ============================================================
# CONTEXTO DA MIA (PERSONALIDADE)
# ============================================================
MIA_SYSTEM_PROMPT = """
Voc√™ √© a Mia, assistente virtual da Legacy Translations, empresa especializada em tradu√ß√µes juramentadas.

**PERSONALIDADE:**
- Profissional, cordial e prestativa
- Use emojis moderadamente (üìÑ, ‚úÖ, üíº, üåç)
- Tom formal mas acess√≠vel

**CAPACIDADES:**
- An√°lise de documentos via imagem (GPT-4 Vision)
- Identifica√ß√£o de tipo de documento
- C√°lculo de pre√ßos de tradu√ß√£o
- Orienta√ß√£o sobre processos

**DOCUMENTOS ACEITOS:**
Certid√£o de Nascimento, Casamento, √ìbito, Diploma, Hist√≥rico Escolar, CNH, RG, Passaporte, Contrato, Procura√ß√£o, etc.

**TABELA DE PRE√áOS (2024):**
- Certid√µes simples: R$ 80-100
- Diplomas: R$ 120-150
- Contratos (por p√°gina): R$ 60-80
- Documentos complexos: consultar

**QUANDO TRANSFERIR PARA HUMANO:**
- Negocia√ß√µes complexas
- Documentos muito t√©cnicos
- Cliente solicita falar com pessoa
- Situa√ß√µes sens√≠veis

**INSTRU√á√ïES:**
1. Sempre pergunte o nome do cliente
2. Se enviar imagem, analise com GPT-4 Vision
3. Identifique o documento e calcule pre√ßo
4. Explique processo e prazo
5. Ofere√ßa finalizar or√ßamento
"""

# ============================================================
# FUN√á√ÉO: BAIXAR M√çDIA DA Z-API
# ============================================================
async def send_whatsapp_message(phone: str, message: str):
    """Envia mensagem via Z-API com Client-Token"""
    try:
        # Construir URL completa
        url = f"https://api.z-api.io/instances/3E4255284F9C20BCBD775E3E11E99CA6/token/4EDA979AE181FE76311C51F5/send-text"
        
        # Headers COM Client-Token
        headers = {
            "Content-Type": "application/json",
            "Client-Token": os.getenv("ZAPI_CLIENT_TOKEN", "")
        }
        
        # Payload
        payload = {
            "phone": phone,
            "message": message
        }
        
        # Logs de debug
        logger.info(f"üîç Enviando para Z-API: {url}")
        logger.info(f"üîç Telefone: {phone}")
        logger.info(f"üîç Client-Token configurado: {'Sim' if headers['Client-Token'] else 'N√£o'}")
        
        # Enviar requisi√ß√£o COM headers
        async with httpx.AsyncClient(timeout=30.0) as client:
            response = await client.post(url, headers=headers, json=payload)
            
            logger.info(f"üîç Status Z-API: {response.status_code}")
            logger.info(f"üîç Resposta Z-API: {response.text}")
            
            if response.status_code == 200:
                logger.info(f"‚úÖ Mensagem enviada com sucesso para {phone}")
                return True
            else:
                logger.error(f"‚ùå Erro ao enviar: {response.status_code} - {response.text}")
                return False
                
    except Exception as e:
        logger.error(f"‚ùå Exce√ß√£o ao enviar para Z-API: {e}")
        return False


# ============================================================
# FUN√á√ÉO: PROCESSAR IMAGEM COM GPT-4 VISION
# ============================================================
async def process_image_with_vision(image_bytes: bytes, phone: str) -> str:
    """
    Analisa imagem usando GPT-4 Vision para identificar documento
    
    Args:
        image_bytes: Bytes da imagem
        phone: Telefone do usu√°rio (para contexto)
    
    Returns:
        str: An√°lise do documento
    """
    try:
        logger.info(f"üîç Analisando imagem com GPT-4 Vision para {phone}")
        
        # Converter para base64
        base64_image = base64.b64encode(image_bytes).decode('utf-8')
        
        # Chamar GPT-4 Vision
        response = openai_client.chat.completions.create(
            model="gpt-4o",
            messages=[
                {
                    "role": "system",
                    "content": """Voc√™ √© um especialista em an√°lise de documentos para tradu√ß√£o juramentada.
                    
                    Analise a imagem e forne√ßa:
                    1. Tipo de documento identificado
                    2. Idioma do documento
                    3. Qualidade da imagem (boa/m√©dia/ruim)
                    4. Se √© adequado para tradu√ß√£o juramentada
                    5. Estimativa de pre√ßo baseado na tabela da Legacy Translations
                    
                    Seja objetivo e profissional."""
                },
                {
                    "role": "user",
                    "content": [
                        {
                            "type": "text",
                            "text": "Analise este documento e me diga que tipo √©, se est√° leg√≠vel e qual seria o pre√ßo aproximado da tradu√ß√£o juramentada."
                        },
                        {
                            "type": "image_url",
                            "image_url": {
                                "url": f"data:image/jpeg;base64,{base64_image}"
                            }
                        }
                    ]
                }
            ],
            max_tokens=500
        )
        
        analysis = response.choices[0].message.content
        logger.info(f"‚úÖ An√°lise conclu√≠da: {analysis[:100]}...")
        
        # Salvar no banco
        await db.documentos.insert_one({
            "phone": phone,
            "timestamp": datetime.now(),
            "analysis": analysis,
            "status": "ANALISADO"
        })
        
        return analysis
        
    except Exception as e:
        logger.error(f"‚ùå Erro ao processar imagem: {str(e)}")
        logger.error(traceback.format_exc())
        return "Desculpe, tive um problema ao analisar a imagem. Pode tentar enviar novamente?"

# ============================================================
# FUN√á√ÉO: PROCESSAR √ÅUDIO COM WHISPER
# ============================================================
async def process_audio_with_whisper(audio_bytes: bytes, phone: str) -> str:
    """
    Transcreve √°udio usando Whisper
    
    Args:
        audio_bytes: Bytes do √°udio
        phone: Telefone do usu√°rio
    
    Returns:
        str: Texto transcrito
    """
    try:
        logger.info(f"üé§ Transcrevendo √°udio com Whisper para {phone}")
        
        # Criar arquivo tempor√°rio em mem√≥ria
        audio_file = BytesIO(audio_bytes)
        audio_file.name = "audio.ogg"
        
        # Transcrever com Whisper
        transcript = openai_client.audio.transcriptions.create(
            model="whisper-1",
            file=audio_file,
            language="pt"
        )
        
        transcription = transcript.text
        logger.info(f"‚úÖ Transcri√ß√£o: {transcription[:100]}...")
        
        return transcription
        
    except Exception as e:
        logger.error(f"‚ùå Erro ao transcrever √°udio: {str(e)}")
        logger.error(traceback.format_exc())
        return None
        return False


# ============================================================
# FUN√á√ÉO: BUSCAR CONTEXTO DA CONVERSA
# ============================================================
async def get_conversation_context(phone: str, limit: int = 10) -> List[Dict]:
    """Busca √∫ltimas mensagens da conversa"""
    try:
        messages = await db.conversas.find(
            {"phone": phone}
        ).sort("timestamp", -1).limit(limit).to_list(length=limit)
        
        # Inverter para ordem cronol√≥gica
        messages.reverse()
        
        return [
            {"role": msg["role"], "content": msg["message"]}
            for msg in messages
        ]
    except Exception as e:
        logger.error(f"‚ùå Erro ao buscar contexto: {str(e)}")
        return []

# ============================================================
# FUN√á√ÉO: PROCESSAR MENSAGEM COM IA
# ============================================================
async def process_message_with_ai(phone: str, message: str) -> str:
    """Processar mensagem com GPT-4"""
    try:
        # Buscar contexto
        context = await get_conversation_context(phone)
        
        # Montar mensagens
        messages = [
            {"role": "system", "content": MIA_SYSTEM_PROMPT}
        ] + context + [
            {"role": "user", "content": message}
        ]
        
        # Chamar GPT-4
        response = openai_client.chat.completions.create(
            model="gpt-4o",
            messages=messages,
            max_tokens=500,
            temperature=0.7
        )
        
        reply = response.choices[0].message.content
        
        # Salvar no banco
        await db.conversas.insert_one({
            "phone": phone,
            "message": message,
            "role": "user",
            "timestamp": datetime.now(),
            "canal": "WhatsApp"
        })
        
        await db.conversas.insert_one({
            "phone": phone,
            "message": reply,
            "role": "assistant",
            "timestamp": datetime.now(),
            "canal": "WhatsApp"
        })
        
        return reply
        
    except Exception as e:
        logger.error(f"‚ùå Erro ao processar com IA: {str(e)}")
        logger.error(traceback.format_exc())
        return "Desculpe, tive um problema. Pode repetir?"

# ============================================================
# WEBHOOK: WHATSAPP (Z-API)
# ============================================================
# ============================================================
# FUN√á√ÉO AUXILIAR: NORMALIZAR TELEFONE
# ============================================================
def normalize_phone(phone: str) -> str:
    """Normaliza n√∫mero de telefone para compara√ß√£o"""
    return ''.join(filter(str.isdigit, phone))[-10:]

# ============================================================
# WEBHOOK: WHATSAPP (Z-API) - INTEGRADO
# ============================================================
@app.post("/webhook/whatsapp")
async def webhook_whatsapp(request: Request):
    """
    Webhook principal para receber mensagens do WhatsApp via Z-API
    Suporta: texto, imagens e √°udios
    """
    try:
        data = await request.json()
        logger.info(f"üì® Webhook recebido: {json.dumps(data, indent=2)}")
        
        # ============================================
        # üõë CONTROLE DE ATIVA√á√ÉO DA IA
        # ============================================
        ia_enabled = os.getenv("IA_ENABLED", "true").lower() == "true"
        em_manutencao = os.getenv("MANUTENCAO", "false").lower() == "true"
        
        # Extrair informa√ß√µes
        phone = data.get("phone", "")
        message_id = data.get("messageId", "")
        connected_phone = data.get("connectedPhone", "")
        is_group = data.get("isGroup", False)
        
        # üö´ FILTRO: Ignorar mensagens de grupos
        if is_group:
            logger.info(f"üö´ Mensagem de grupo ignorada")
            return JSONResponse({"status": "ignored", "reason": "group message"})
        
        message_type = data.get("messageType", "text")
        
        if not phone:
            return JSONResponse({"status": "ignored", "reason": "no phone"})
        
        # Se em manuten√ß√£o, responder e sair
        if em_manutencao:
            logger.info(f"üîß Modo manuten√ß√£o ativo - mensagem de {phone}")
            if message_type == "text":
                mensagem_manutencao = """üîß *Sistema em Manuten√ß√£o*\n\nOl√°! Estamos melhorando nosso atendimento.\nEm breve voltaremos! üòä\n\nüìû Para urg√™ncias: (contato)"""
                await send_whatsapp_message(phone, mensagem_manutencao)
            return JSONResponse({"status": "maintenance"})
        
        # Se IA desabilitada, apenas logar e sair
        if not ia_enabled:
            logger.info(f"‚è∏Ô∏è IA desabilitada - mensagem de {phone} ignorada")
            return JSONResponse({"status": "ia_disabled"})
        # ============================================
        
        # ========== PROCESSAR TEXTO ==========
        if message_type == "text":
            text = data.get("text", {}).get("message", "")
            
            if not text:
                return JSONResponse({"status": "ignored", "reason": "empty text"})
            
            logger.info(f"üí¨ Texto de {phone}: {text}")
            
            # ============================================
            # ü§ñ PROCESSAR COM IA (modo normal)
            # ============================================
            
            
            # Processar com IA
            reply = await process_message_with_ai(phone, text)
            
            # ============================================
            # ‚úÖ ENVIAR RESPOSTA
            # ============================================
            
            # Enviar resposta
            await send_whatsapp_message(phone, reply)
            
            return JSONResponse({"status": "processed", "type": "text"})
        
        # ========== PROCESSAR IMAGEM ==========
        elif message_type == "image":
            image_url = data.get("image", {}).get("imageUrl", "")
            caption = data.get("image", {}).get("caption", "")
            
            if not image_url:
                return JSONResponse({"status": "ignored", "reason": "no image url"})
            
            logger.info(f"üñºÔ∏è Imagem de {phone}: {image_url[:50]}")
            
            # Baixar imagem
            image_bytes = await download_media_from_zapi(image_url)
            
            if not image_bytes:
                await send_whatsapp_message(phone, "Desculpe, n√£o consegui baixar a imagem. Pode tentar enviar novamente?")
                return JSONResponse({"status": "error", "reason": "download failed"})
            
            # Analisar com Vision
            analysis = await process_image_with_vision(image_bytes, phone)
            
            # Montar resposta
            reply = f"üìÑ *An√°lise do Documento*\n\n{analysis}\n\n_Posso ajudar com mais alguma coisa?_"
            
            # Enviar resposta
            await send_whatsapp_message(phone, reply)
            
            return JSONResponse({"status": "processed", "type": "image"})
        
        # ========== PROCESSAR √ÅUDIO ==========
        elif message_type == "audio":
            audio_url = data.get("audio", {}).get("audioUrl", "")
            
            if not audio_url:
                return JSONResponse({"status": "ignored", "reason": "no audio url"})
            
            logger.info(f"üé§ √Åudio de {phone}: {audio_url[:50]}")
            
            # Baixar √°udio
            audio_bytes = await download_media_from_zapi(audio_url)
            
            if not audio_bytes:
                await send_whatsapp_message(phone, "Desculpe, n√£o consegui baixar o √°udio. Pode tentar enviar novamente?")
                return JSONResponse({"status": "error", "reason": "download failed"})
            
            # Transcrever com Whisper
            transcription = await process_audio_with_whisper(audio_bytes, phone)
            
            if not transcription:
                await send_whatsapp_message(phone, "Desculpe, n√£o consegui entender o √°udio. Pode escrever ou enviar novamente?")
                return JSONResponse({"status": "error", "reason": "transcription failed"})
            
            logger.info(f"üìù Transcri√ß√£o: {transcription}")
            
            # Processar transcri√ß√£o com IA
            reply = await process_message_with_ai(phone, transcription)
            
            # Enviar resposta
            await send_whatsapp_message(phone, reply)
            
            return JSONResponse({"status": "processed", "type": "audio"})
        
        else:
            logger.info(f"‚ö†Ô∏è Tipo n√£o suportado: {message_type}")
            return JSONResponse({"status": "ignored", "reason": f"unsupported type: {message_type}"})
            
    except Exception as e:
        logger.error(f"‚ùå Erro no webhook: {str(e)}")
        logger.error(traceback.format_exc())
        return JSONResponse({"status": "error", "message": str(e)}, status_code=500)

# ============================================================
# ROTA: HEALTH CHECK
# ============================================================
@app.get("/health")
async def health_check():
    """Health check endpoint"""
    try:
        # Testar MongoDB
        await db.command("ping")
        
        return {
            "status": "healthy",
            "timestamp": datetime.now().isoformat(),
            "openai": "‚úÖ Configurado" if os.getenv("OPENAI_API_KEY") else "‚ùå N√£o configurado",
            "mongodb": "‚úÖ Conectado",
            "zapi_instance": "‚úÖ Configurado" if ZAPI_INSTANCE_ID else "‚ùå N√£o configurado",
            "zapi_token": "‚úÖ Configurado" if ZAPI_TOKEN else "‚ùå N√£o configurado"
        }
    except Exception as e:
        return JSONResponse(
            {"status": "unhealthy", "error": str(e)},
            status_code=503
        )

# ============================================================
# ROTA RAIZ
# ============================================================
@app.get("/")
async def root():
    """Redirecionar para painel admin"""
    return RedirectResponse(url="/admin")

# ============================================================
# STARTUP
# ============================================================
@app.on_event("startup")
async def startup_event():
    """Evento de inicializa√ß√£o"""
    logger.info("=" * 60)
    logger.info("üöÄ WhatsApp AI Platform - Legacy Translations")
    logger.info("üì¶ VERS√ÉO MULTIM√çDIA + ADMIN 2.0")
    logger.info("=" * 60)
    logger.info(f"‚úÖ OpenAI: {'Configurado' if os.getenv('OPENAI_API_KEY') else '‚ùå FALTANDO'}")
    logger.info(f"‚úÖ MongoDB: {'Configurado' if os.getenv('MONGODB_URI') else '‚ùå FALTANDO'}")
    logger.info(f"‚úÖ Z-API Instance: {'Configurado' if ZAPI_INSTANCE_ID else '‚ùå FALTANDO'}")
    logger.info(f"‚úÖ Z-API Token: {'Configurado' if ZAPI_TOKEN else '‚ùå FALTANDO'}")
    logger.info("=" * 60)
    logger.info("üéØ FUNCIONALIDADES ATIVAS:")
    logger.info("   ‚úÖ Mensagens de texto")
    logger.info("   ‚úÖ Imagens (GPT-4 Vision)")
    logger.info("   ‚úÖ √Åudios (Whisper)")
    logger.info("   ‚úÖ Painel Admin Completo")
    logger.info("   ‚úÖ Controle IA vs Humano")
    logger.info("=" * 60)

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)
    # ============================================================
# ROTA DE DIAGN√ìSTICO TEMPOR√ÅRIA
# ============================================================
import os
from pathlib import Path
from fastapi.responses import HTMLResponse

@app.get("/diagnostic/templates", response_class=HTMLResponse)
async def diagnostic_templates():
    """Diagn√≥stico completo de templates"""
    
    html_parts = ["<html><head><style>body{font-family:monospace;padding:20px;background:#1a1a1a;color:#0f0;}pre{background:#000;padding:10px;border:1px solid #0f0;}</style></head><body>"]
    html_parts.append("<h1>üîç DIAGN√ìSTICO DE TEMPLATES</h1>")
    
    # 1. Diret√≥rio atual
    html_parts.append("<h2>üìÅ Diret√≥rio de trabalho:</h2>")
    html_parts.append(f"<pre>{os.getcwd()}</pre>")
    
    # 2. Listar pasta templates
    html_parts.append("<h2>üìÇ Conte√∫do da pasta templates/:</h2>")
    templates_path = Path("templates")
    if templates_path.exists():
        html_parts.append("<pre>")
        for file in sorted(templates_path.rglob("*")):
            if file.is_file():
                size = file.stat().st_size
                html_parts.append(f"{file.relative_to('.')} - {size:,} bytes\n")
        html_parts.append("</pre>")
    else:
        html_parts.append("<pre style='color:red;'>‚ùå PASTA TEMPLATES N√ÉO EXISTE!</pre>")
    
    # 3. Procurar arquivos treinamento
    html_parts.append("<h2>üîé Procurando arquivos com 'treinamento' ou 'training':</h2>")
    html_parts.append("<pre>")
    for pattern in ["*treinamento*", "*training*"]:
        for file in Path(".").rglob(pattern):
            html_parts.append(f"{file} - {'DIR' if file.is_dir() else f'{file.stat().st_size} bytes'}\n")
    html_parts.append("</pre>")
    
    # 4. Listar TODOS arquivos .html no projeto
    html_parts.append("<h2>üìÑ TODOS os arquivos .html no projeto:</h2>")
    html_parts.append("<pre>")
    for file in Path(".").rglob("*.html"):
        size = file.stat().st_size
        html_parts.append(f"{file} - {size:,} bytes\n")
    html_parts.append("</pre>")
    
    html_parts.append("</body></html>")
    return "".join(html_parts)
@app.get("/diagnostic/jinja", response_class=HTMLResponse)
async def diagnostic_jinja():
    """Diagn√≥stico configura√ß√£o Jinja2"""
    
    html_parts = ["<html><head><style>body{font-family:monospace;padding:20px;background:#1a1a1a;color:#0f0;}pre{background:#000;padding:10px;border:1px solid #0f0;}</style></head><body>"]
    html_parts.append("<h1>üîç DIAGN√ìSTICO JINJA2</h1>")
    
    # 1. Verificar objeto templates do main
    html_parts.append("<h2>üì¶ Objeto 'templates' do main.py:</h2>")
    try:
        html_parts.append(f"<pre>Type: {type(templates)}\n")
        html_parts.append(f"Directory: {templates.directory if hasattr(templates, 'directory') else 'N/A'}\n")
        if hasattr(templates, 'env') and hasattr(templates.env, 'loader'):
            loader = templates.env.loader
            html_parts.append(f"Loader: {type(loader)}\n")
            if hasattr(loader, 'searchpath'):
                html_parts.append(f"Searchpath: {loader.searchpath}\n")
        html_parts.append("</pre>")
    except Exception as e:
        html_parts.append(f"<pre style='color:red;'>‚ùå Erro: {e}</pre>")
    
    # 2. Verificar objeto templates do admin_training_routes
    html_parts.append("<h2>üì¶ Objeto 'templates' do admin_training_routes.py:</h2>")
    try:
        from admin_training_routes import templates as training_templates
        html_parts.append(f"<pre>Type: {type(training_templates)}\n")
        html_parts.append(f"Directory: {training_templates.directory if hasattr(training_templates, 'directory') else 'N/A'}\n")
        if hasattr(training_templates, 'env') and hasattr(training_templates.env, 'loader'):
            loader = training_templates.env.loader
            html_parts.append(f"Loader: {type(loader)}\n")
            if hasattr(loader, 'searchpath'):
                html_parts.append(f"Searchpath: {loader.searchpath}\n")
        html_parts.append("</pre>")
    except Exception as e:
        html_parts.append(f"<pre style='color:red;'>‚ùå Erro ao importar: {e}</pre>")
    
    # 3. Tentar renderizar manualmente
    html_parts.append("<h2>üß™ Teste de renderiza√ß√£o manual:</h2>")
    try:
        from jinja2 import Environment, FileSystemLoader
        import os
        
        template_dir = os.path.join(os.getcwd(), "templates")
        html_parts.append(f"<pre>Template dir absoluto: {template_dir}\n")
        html_parts.append(f"Dir existe? {os.path.exists(template_dir)}\n")
        
        env = Environment(loader=FileSystemLoader(template_dir))
        html_parts.append(f"Templates dispon√≠veis: {env.list_templates()[:20]}\n")
        
        # Tentar carregar admin_treinamento.html
        template = env.get_template("admin_treinamento.html")
        html_parts.append(f"‚úÖ Template carregado com sucesso!\n")
        html_parts.append(f"Template name: {template.name}\n")
        html_parts.append("</pre>")
    except Exception as e:
        html_parts.append(f"<pre style='color:red;'>‚ùå Erro: {e}</pre>")
    
    html_parts.append("</body></html>")
    return "".join(html_parts)

